{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a22a04-1665-4ea8-b1a4-e0172ce1a30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Offline Ï¶ùÍ∞ï] Îç∞Ïù¥ÌÑ∞Í∞Ä Ïù¥ÎØ∏ Ï¶ùÍ∞ïÎêòÏóàÏäµÎãàÎã§.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available üòÉ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=250423_010540_Train, mode=train, model=yolov9t.yaml, data=Datasets/CV_Competition/data_iter_01.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=tmp, name=250423_010545_yolov9t_CV_Competition_Iter_1, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.9, weight_decay=5e-05, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp/250423_010545_yolov9t_CV_Competition_Iter_1\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567187  ultralytics.nn.modules.head.Detect           [1, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,603 parameters, 2,005,587 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir tmp/250423_010545_yolov9t_CV_Competition_Iter_1', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 906 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 906/906 [00:00<00:00, 2537.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:00<00:00, 2275.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tmp/250423_010545_yolov9t_CV_Competition_Iter_1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=5e-05), 227 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mtmp/250423_010545_yolov9t_CV_Competition_Iter_1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      5.28G      3.206      3.253      3.615         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00536       0.49     0.0116    0.00234\n",
      "\n",
      "1 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from tmp/250423_010545_yolov9t_CV_Competition_Iter_1/weights/last.pt, 4.6MB\n",
      "Optimizer stripped from tmp/250423_010545_yolov9t_CV_Competition_Iter_1/weights/best.pt, 4.6MB\n",
      "\n",
      "Validating tmp/250423_010545_yolov9t_CV_Competition_Iter_1/weights/best.pt...\n",
      "Ultralytics 8.3.96 üöÄ Python-3.10.17 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 48520MiB)\n",
      "YOLOv9t summary (fused): 197 layers, 1,970,979 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00534       0.49     0.0112     0.0022\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mtmp/250423_010545_yolov9t_CV_Competition_Iter_1\u001b[0m\n",
      "Transferred 1339/1339 items from pretrained weights\n",
      "Í≤∞Í≥ºÍ∞Ä 250423_010540_submission_1_20224397_Iter_1_detection_results.jsonÏóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\n",
      "[Offline Ï¶ùÍ∞ï] Îç∞Ïù¥ÌÑ∞Í∞Ä Ïù¥ÎØ∏ Ï¶ùÍ∞ïÎêòÏóàÏäµÎãàÎã§.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available üòÉ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=250423_010626_Train, mode=train, model=yolov9t.yaml, data=Datasets/CV_Competition/data_iter_01.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=tmp, name=250423_010628_yolov9t_CV_Competition_Iter_1, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.9, weight_decay=5e-05, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp/250423_010628_yolov9t_CV_Competition_Iter_1\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567187  ultralytics.nn.modules.head.Detect           [1, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,603 parameters, 2,005,587 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir tmp/250423_010628_yolov9t_CV_Competition_Iter_1', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 906 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 906/906 [00:00<00:00, 2358.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:00<00:00, 2536.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tmp/250423_010628_yolov9t_CV_Competition_Iter_1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=5e-05), 227 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mtmp/250423_010628_yolov9t_CV_Competition_Iter_1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      5.28G      3.206      3.253      3.615         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00536       0.49     0.0116    0.00234\n",
      "\n",
      "1 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from tmp/250423_010628_yolov9t_CV_Competition_Iter_1/weights/last.pt, 4.6MB\n",
      "Optimizer stripped from tmp/250423_010628_yolov9t_CV_Competition_Iter_1/weights/best.pt, 4.6MB\n",
      "\n",
      "Validating tmp/250423_010628_yolov9t_CV_Competition_Iter_1/weights/best.pt...\n",
      "Ultralytics 8.3.96 üöÄ Python-3.10.17 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 48520MiB)\n",
      "YOLOv9t summary (fused): 197 layers, 1,970,979 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00534       0.49     0.0112     0.0022\n",
      "Speed: 0.1ms preprocess, 0.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mtmp/250423_010628_yolov9t_CV_Competition_Iter_1\u001b[0m\n",
      "Transferred 1339/1339 items from pretrained weights\n",
      "Í≤∞Í≥ºÍ∞Ä 250423_010626_submission_2_20224397_Iter_1_detection_results.jsonÏóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\n",
      "[Offline Ï¶ùÍ∞ï] Îç∞Ïù¥ÌÑ∞Í∞Ä Ïù¥ÎØ∏ Ï¶ùÍ∞ïÎêòÏóàÏäµÎãàÎã§.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available üòÉ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=250423_010659_Train, mode=train, model=yolov9t.yaml, data=Datasets/CV_Competition/data_iter_01.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=tmp, name=250423_010702_yolov9t_CV_Competition_Iter_1, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.9, weight_decay=5e-05, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp/250423_010702_yolov9t_CV_Competition_Iter_1\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567187  ultralytics.nn.modules.head.Detect           [1, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,603 parameters, 2,005,587 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir tmp/250423_010702_yolov9t_CV_Competition_Iter_1', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 906 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 906/906 [00:00<00:00, 2522.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:00<00:00, 1193.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tmp/250423_010702_yolov9t_CV_Competition_Iter_1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=5e-05), 227 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mtmp/250423_010702_yolov9t_CV_Competition_Iter_1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      5.28G      3.206      3.253      3.615         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:07<00:00,  7.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00536       0.49     0.0116    0.00234\n",
      "\n",
      "1 epochs completed in 0.005 hours.\n",
      "Optimizer stripped from tmp/250423_010702_yolov9t_CV_Competition_Iter_1/weights/last.pt, 4.6MB\n",
      "Optimizer stripped from tmp/250423_010702_yolov9t_CV_Competition_Iter_1/weights/best.pt, 4.6MB\n",
      "\n",
      "Validating tmp/250423_010702_yolov9t_CV_Competition_Iter_1/weights/best.pt...\n",
      "Ultralytics 8.3.96 üöÄ Python-3.10.17 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 48520MiB)\n",
      "YOLOv9t summary (fused): 197 layers, 1,970,979 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00534       0.49     0.0112     0.0022\n",
      "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mtmp/250423_010702_yolov9t_CV_Competition_Iter_1\u001b[0m\n",
      "Transferred 1339/1339 items from pretrained weights\n",
      "Í≤∞Í≥ºÍ∞Ä 250423_010659_submission_3_20224397_Iter_1_detection_results.jsonÏóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\n",
      "[Offline Ï¶ùÍ∞ï] Îç∞Ïù¥ÌÑ∞Í∞Ä Ïù¥ÎØ∏ Ï¶ùÍ∞ïÎêòÏóàÏäµÎãàÎã§.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available üòÉ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=250423_010736_Train, mode=train, model=yolov9t.yaml, data=Datasets/CV_Competition/data_iter_02.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=tmp, name=250423_010739_yolov9t_CV_Competition_Iter_2, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.9, weight_decay=5e-05, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp/250423_010739_yolov9t_CV_Competition_Iter_2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567187  ultralytics.nn.modules.head.Detect           [1, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,603 parameters, 2,005,587 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir tmp/250423_010739_yolov9t_CV_Competition_Iter_2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 906 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 906/906 [00:00<00:00, 2419.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:00<00:00, 2648.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tmp/250423_010739_yolov9t_CV_Competition_Iter_2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=5e-05), 227 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mtmp/250423_010739_yolov9t_CV_Competition_Iter_2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      5.28G      3.196      3.266      3.593         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:08<00:00,  7.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00224      0.669     0.0138    0.00275\n",
      "\n",
      "1 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from tmp/250423_010739_yolov9t_CV_Competition_Iter_2/weights/last.pt, 4.6MB\n",
      "Optimizer stripped from tmp/250423_010739_yolov9t_CV_Competition_Iter_2/weights/best.pt, 4.6MB\n",
      "\n",
      "Validating tmp/250423_010739_yolov9t_CV_Competition_Iter_2/weights/best.pt...\n",
      "Ultralytics 8.3.96 üöÄ Python-3.10.17 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 48520MiB)\n",
      "YOLOv9t summary (fused): 197 layers, 1,970,979 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00226      0.675     0.0138    0.00275\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mtmp/250423_010739_yolov9t_CV_Competition_Iter_2\u001b[0m\n",
      "Transferred 1339/1339 items from pretrained weights\n",
      "Í≤∞Í≥ºÍ∞Ä 250423_010736_submission_1_20224397_Iter_2_detection_results.jsonÏóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\n",
      "[Offline Ï¶ùÍ∞ï] Îç∞Ïù¥ÌÑ∞Í∞Ä Ïù¥ÎØ∏ Ï¶ùÍ∞ïÎêòÏóàÏäµÎãàÎã§.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available üòÉ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=250423_010816_Train, mode=train, model=yolov9t.yaml, data=Datasets/CV_Competition/data_iter_02.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=tmp, name=250423_010820_yolov9t_CV_Competition_Iter_2, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.9, weight_decay=5e-05, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp/250423_010820_yolov9t_CV_Competition_Iter_2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567187  ultralytics.nn.modules.head.Detect           [1, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,603 parameters, 2,005,587 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir tmp/250423_010820_yolov9t_CV_Competition_Iter_2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 906 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 906/906 [00:00<00:00, 2630.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:00<00:00, 2197.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tmp/250423_010820_yolov9t_CV_Competition_Iter_2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=5e-05), 227 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mtmp/250423_010820_yolov9t_CV_Competition_Iter_2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      5.28G      3.196      3.266      3.593         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:08<00:00,  6.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00224      0.669     0.0138    0.00275\n",
      "\n",
      "1 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from tmp/250423_010820_yolov9t_CV_Competition_Iter_2/weights/last.pt, 4.6MB\n",
      "Optimizer stripped from tmp/250423_010820_yolov9t_CV_Competition_Iter_2/weights/best.pt, 4.6MB\n",
      "\n",
      "Validating tmp/250423_010820_yolov9t_CV_Competition_Iter_2/weights/best.pt...\n",
      "Ultralytics 8.3.96 üöÄ Python-3.10.17 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX 6000 Ada Generation, 48520MiB)\n",
      "YOLOv9t summary (fused): 197 layers, 1,970,979 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        151    0.00226      0.675     0.0138    0.00275\n",
      "Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mtmp/250423_010820_yolov9t_CV_Competition_Iter_2\u001b[0m\n",
      "Transferred 1339/1339 items from pretrained weights\n",
      "Í≤∞Í≥ºÍ∞Ä 250423_010816_submission_2_20224397_Iter_2_detection_results.jsonÏóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\n",
      "[Offline Ï¶ùÍ∞ï] Îç∞Ïù¥ÌÑ∞Í∞Ä Ïù¥ÎØ∏ Ï¶ùÍ∞ïÎêòÏóàÏäµÎãàÎã§.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available üòÉ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=250423_010857_Train, mode=train, model=yolov9t.yaml, data=Datasets/CV_Competition/data_iter_02.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=tmp, name=250423_010900_yolov9t_CV_Competition_Iter_2, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.9, weight_decay=5e-05, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp/250423_010900_yolov9t_CV_Competition_Iter_2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567187  ultralytics.nn.modules.head.Detect           [1, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,603 parameters, 2,005,587 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir tmp/250423_010900_yolov9t_CV_Competition_Iter_2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 906 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 906/906 [00:00<00:00, 2591.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151/151 [00:00<00:00, 2156.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data3/jykim/Projects/image/Finetuning/Datasets/CV_Competition/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tmp/250423_010900_yolov9t_CV_Competition_Iter_2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=5e-05), 227 bias(decay=0.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m ex_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m output_json_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubmission_function\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Iter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_detection_results.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43msubmission_function\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_json_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m labels_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDataset_Name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/labels\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m     31\u001b[0m vis_output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_visualization_results\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n",
      "File \u001b[0;32m~/Projects/image/Finetuning/submission_3_20224397.py:92\u001b[0m, in \u001b[0;36msubmission_3_20224397\u001b[0;34m(yaml_path, output_json_path)\u001b[0m\n\u001b[1;32m     90\u001b[0m ex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model_name\n\u001b[1;32m     91\u001b[0m ex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mmodel\n\u001b[0;32m---> 92\u001b[0m ex_dict \u001b[38;5;241m=\u001b[39m \u001b[43mYOLOvN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m test_images \u001b[38;5;241m=\u001b[39m get_test_images(data_config)\n\u001b[1;32m     94\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m YOLOvN\u001b[38;5;241m.\u001b[39mdetect_and_save_bboxes(ex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m], test_images, confidence)\n",
      "File \u001b[0;32m~/Projects/image/Finetuning/models/YOLOvN/YOLOvN.py:16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(ex_dict)\u001b[0m\n\u001b[1;32m     13\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Iter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiment Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m ex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Results\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData Config\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEpochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage Size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBatch Size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeight Decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mex_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOutput Dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m pt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput Dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m ex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPT path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pt_path\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/ultralytics/engine/model.py:791\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/ultralytics/engine/trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/ultralytics/engine/trainer.py:334\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage sizes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m val\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader\u001b[38;5;241m.\u001b[39mnum_workers\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m(world_size\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataloader workers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogging results to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolorstr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training for \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hours...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m )\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mclose_mosaic:\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/ultralytics/engine/trainer.py:172\u001b[0m, in \u001b[0;36mBaseTrainer.run_callbacks\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run all existing callbacks associated with a particular event.\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mget(event, []):\n\u001b[0;32m--> 172\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/ultralytics/utils/callbacks/tensorboard.py:83\u001b[0m, in \u001b[0;36mon_train_start\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Log TensorBoard graph.\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m WRITER:\n\u001b[0;32m---> 83\u001b[0m     \u001b[43m_log_tensorboard_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/ultralytics/utils/callbacks/tensorboard.py:48\u001b[0m, in \u001b[0;36m_log_tensorboard_graph\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# place in .eval() mode to avoid BatchNorm statistics changes\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     WRITER\u001b[38;5;241m.\u001b[39madd_graph(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mde_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, [])\n\u001b[1;32m     49\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPREFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mmodel graph visualization added ‚úÖ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:1000\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    987\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`optimize` is deprecated and has no effect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `with torch.jit.optimized_execution()` instead\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    991\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    992\u001b[0m     )\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    995\u001b[0m     check_if_torch_exportable,\n\u001b[1;32m    996\u001b[0m     log_torch_jit_trace_exportability,\n\u001b[1;32m    997\u001b[0m     log_torchscript_usage,\n\u001b[1;32m    998\u001b[0m )\n\u001b[0;32m-> 1000\u001b[0m traced_func \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m log_torchscript_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_id\u001b[38;5;241m=\u001b[39m_get_model_id(traced_func))\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_if_torch_exportable():\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:696\u001b[0m, in \u001b[0;36m_trace_impl\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    713\u001b[0m ):\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:1241\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_trace\u001b[38;5;241m.\u001b[39m_trace_module_map \u001b[38;5;241m=\u001b[39m trace_module_map\n\u001b[1;32m   1239\u001b[0m register_submods(mod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__module\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mmake_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method_name, example_inputs \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;66;03m# \"forward\" is a special case because we need to trace\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# `Module.__call__`, which sets up some extra tracing, but uses\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# argument names of the real `Module.forward` method.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:629\u001b[0m, in \u001b[0;36mmake_module\u001b[0;34m(mod, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _module_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     _module_class \u001b[38;5;241m=\u001b[39m TopLevelTracedModule\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_module_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:1391\u001b[0m, in \u001b[0;36mTracedModule.__init__\u001b[0;34m(self, orig, id_set, _compilation_unit)\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m submodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1390\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1391\u001b[0m     tmp_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m \u001b[43mmake_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTracedModule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1395\u001b[0m script_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_recursive\u001b[38;5;241m.\u001b[39mcreate_script_module(\n\u001b[1;32m   1396\u001b[0m     tmp_module, \u001b[38;5;28;01mlambda\u001b[39;00m module: (), share_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_tracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m )\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(orig)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:629\u001b[0m, in \u001b[0;36mmake_module\u001b[0;34m(mod, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _module_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     _module_class \u001b[38;5;241m=\u001b[39m TopLevelTracedModule\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_module_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:1391\u001b[0m, in \u001b[0;36mTracedModule.__init__\u001b[0;34m(self, orig, id_set, _compilation_unit)\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m submodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1390\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1391\u001b[0m     tmp_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m \u001b[43mmake_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTracedModule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1395\u001b[0m script_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_recursive\u001b[38;5;241m.\u001b[39mcreate_script_module(\n\u001b[1;32m   1396\u001b[0m     tmp_module, \u001b[38;5;28;01mlambda\u001b[39;00m module: (), share_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_tracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m )\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(orig)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: make_module at line 629 (2 times), TracedModule.__init__ at line 1391 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:1391\u001b[0m, in \u001b[0;36mTracedModule.__init__\u001b[0;34m(self, orig, id_set, _compilation_unit)\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m submodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1390\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1391\u001b[0m     tmp_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m \u001b[43mmake_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTracedModule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1395\u001b[0m script_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_recursive\u001b[38;5;241m.\u001b[39mcreate_script_module(\n\u001b[1;32m   1396\u001b[0m     tmp_module, \u001b[38;5;28;01mlambda\u001b[39;00m module: (), share_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_tracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m )\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(orig)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:629\u001b[0m, in \u001b[0;36mmake_module\u001b[0;34m(mod, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _module_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     _module_class \u001b[38;5;241m=\u001b[39m TopLevelTracedModule\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_module_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_trace.py:1395\u001b[0m, in \u001b[0;36mTracedModule.__init__\u001b[0;34m(self, orig, id_set, _compilation_unit)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m     tmp_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m make_module(\n\u001b[1;32m   1392\u001b[0m         submodule, TracedModule, _compilation_unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m     )\n\u001b[0;32m-> 1395\u001b[0m script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmp_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_tracing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   1397\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(orig)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_actual_script_module\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m script_module\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_recursive.py:557\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    556\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/jit/_recursive.py:703\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    699\u001b[0m     script_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[property_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mproperty\u001b[39m(property_name, fget, fset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# copy over python methods to script module if they aren't defined on the script module\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# this is currently an internal api used only on module containers\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m ignored_properties:\n\u001b[1;32m    705\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/image/lib/python3.10/site-packages/torch/nn/modules/module.py:2957\u001b[0m, in \u001b[0;36mModule.__dir__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2956\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__dir__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2957\u001b[0m     module_attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2958\u001b[0m     attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   2959\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from competition_utils import *\n",
    "\n",
    "# Ï†úÏ∂ú Ìï®ÏàòÎ•º Î¶¨Ïä§Ìä∏Î°ú Ï†ïÏùò (submission_N_ÌïôÎ≤à)\n",
    "# ÍπÉÌóàÎ∏åÏóêÎäî ÏµúÎåÄ 3Í∞ú ÏóÖÎ°úÎìú Îç∞Î™®Ïãú ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù ÌõÑ 1Í∞úÎßå Ï†úÏ∂ú\n",
    "submission_functions = ['submission_1_20224397', 'submission_2_20224397', 'submission_3_20224397']  \n",
    "for submission_function in submission_functions:\n",
    "    exec(f\"from {submission_function} import {submission_function}\")\n",
    "\n",
    "# Î∂ÑÏÑù Î∞©Ìñ•Ïóê Îî∞Îùº iteration Ïàò ÏàòÏ†ï\n",
    "# ÌèâÍ∞ÄÏãúÏóêÎäî Îç∞Î™®ÏôÄ Îã§Î•∏ Ïä§ÌîåÎ¶ø ÏãúÎìúÎ•º ÎßåÎì§Ïñ¥ [1, 10]Î°ú ÏßÑÌñâ ÏòàÏ†ï\n",
    "iterations = [1, 10] \n",
    "\n",
    "# 'Crown Detection'Îäî ÏòàÏ†ú Îç∞Ïù¥ÌÑ∞ÏÖã, Îç∞Î™® Î∞è ÌèâÍ∞ÄÏãúÏóêÎäî 'CV_Competition'\n",
    "Dataset_Name = 'CV_Competition' \n",
    "\n",
    "# Í≤∞Í≥ºÎ•º Î™®ÏïÑ ÌïòÎÇòÏùò csv ÌååÏùºÏóê Ï†ÄÏû•\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Experiment Time', 'Iteration', 'Submission Function', \n",
    "    'IoU', 'Dice', 'Precision', 'Recall', 'Output Json Path',\n",
    "])\n",
    "csv_filename = f\"Evaluation_Results_{datetime.now().strftime('%y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "# ÏÑúÎ°ú Îã§Î•∏ iteration, submission functionÏúºÎ°ú Ïã§Ìóò ÏßÑÌñâ\n",
    "for iteration in range(iterations[0], iterations[1]+1):\n",
    "    yaml_path = f'Datasets/{Dataset_Name}/data_iter_{iteration:02d}.yaml'\n",
    "    for submission_function in submission_functions:\n",
    "        ex_time = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "        output_json_path = f\"{ex_time}_{submission_function}_Iter_{iteration}_detection_results.json\"\n",
    "        globals()[submission_function](yaml_path, output_json_path)\n",
    "        labels_dir = f\"Datasets/{Dataset_Name}/labels\"  \n",
    "        vis_output_dir = f\"{ex_time}_visualization_results\"  \n",
    "        image_level_result_path =f\"{ex_time}_{submission_function}_Iter_{iteration}_image_level_results.json\"\n",
    "        stats = eval_and_vis(yaml_path, output_json_path, labels_dir, image_level_result_path, vis_output_dir, vis=False) # Î∂ÑÏÑù Î∞©Ìñ•Ïóê Îî∞Îùº vis=True ÏÑ§Ï†ï\n",
    "        new_row = {\n",
    "            'Experiment Time': ex_time,\n",
    "            'Iteration': iteration,\n",
    "            'Submission Function': submission_function,\n",
    "            'IoU': stats['IoU']['avg'],\n",
    "            'Dice': stats['Dice']['avg'],\n",
    "            'Precision': stats['Precision']['avg'],\n",
    "            'Recall': stats['Recall']['avg'],\n",
    "            'Output Json Path': output_json_path,\n",
    "        }\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        results_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42711cc-d6dc-49db-b7cd-d9ebc4a9f596",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m decimal_places \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     14\u001b[0m transpose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmake_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_measures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreference_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_fmt_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignificance_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimal_places\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/image/Finetuning/competition_utils.py:446\u001b[0m, in \u001b[0;36mmake_tables\u001b[0;34m(input_csv_path, keep_columns, keep_measures, reduction, row, column, null_column, custom_fmt_template, significance_levels, decimal_places, transpose)\u001b[0m\n\u001b[1;32m    443\u001b[0m second_df, null_column \u001b[38;5;241m=\u001b[39m filter_and_transform_formal_name(df, row, column, rename_row, rename_col, null_column)\n\u001b[1;32m    445\u001b[0m third_df \u001b[38;5;241m=\u001b[39m second_df\n\u001b[0;32m--> 446\u001b[0m fourth_df \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_row_column_combinations_with_ranking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthird_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43munique_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthird_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mranking_order_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mranking_order_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnull_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnull_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignificance_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignificance_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal_places\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal_places\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_fmt_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_fmt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m fourth_df \u001b[38;5;241m=\u001b[39m reorder_dataframe(fourth_df, rename_col, rename_row)\n\u001b[1;32m    458\u001b[0m fourth_df \u001b[38;5;241m=\u001b[39m fourth_df\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m transpose \u001b[38;5;28;01melse\u001b[39;00m fourth_df\n",
      "File \u001b[0;32m~/Projects/image/Finetuning/competition_utils.py:405\u001b[0m, in \u001b[0;36manalyze_row_column_combinations_with_ranking\u001b[0;34m(df, row, column, unique_columns, ranking_order_list, null_column, significance_levels, decimal_places, custom_fmt_template)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip if no valid data is present\u001b[39;00m\n\u001b[1;32m    403\u001b[0m value_matrix \u001b[38;5;241m=\u001b[39m [[values_by_column[c][idx] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m unique_columns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values_by_column[c]) \u001b[38;5;241m>\u001b[39m idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(common_length)]\n\u001b[0;32m--> 405\u001b[0m ranked_results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_ranks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues_by_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranking_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m null_values \u001b[38;5;241m=\u001b[39m values_by_column\u001b[38;5;241m.\u001b[39mget(null_column, [])\n\u001b[1;32m    407\u001b[0m significance_annotations \u001b[38;5;241m=\u001b[39m perform_paired_t_tests(null_values, values_by_column, unique_columns, null_column, significance_levels, common_length)\n",
      "File \u001b[0;32m~/Projects/image/Finetuning/competition_utils.py:364\u001b[0m, in \u001b[0;36mcalculate_ranks\u001b[0;34m(value_matrix_dict, ranking_order)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Convert dictionary to matrix (list of rows where each row is one iteration's values across columns)\u001b[39;00m\n\u001b[1;32m    363\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(value_matrix_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m--> 364\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue_matrix_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# Transpose to make rows represent iterations\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Calculate ranks for each row\u001b[39;00m\n\u001b[1;32m    367\u001b[0m ranks_per_row \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    368\u001b[0m     rankdata(row \u001b[38;5;28;01mif\u001b[39;00m ranking_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124masc\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;241m-\u001b[39mval \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m row])\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m matrix\n\u001b[1;32m    370\u001b[0m ]\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Î∂ÑÏÑù Î∞©Ìñ•Ïóê Îî∞Îùº Ï†ÑÏ≤¥ Í≤∞Í≥ºÎ•º Î™®ÏïÑ ÌèâÍ∑†-ÌëúÏ§ÄÌé∏Ï∞®-ÌÜµÍ≥ÑÌÖåÏä§Ìä∏ Í≤∞Í≥º Ï†ÄÏû• \n",
    "\n",
    "keep_columns = ['Iteration','Submission Function']\n",
    "keep_measures = ['IoU','Dice','Precision','Recall']  \n",
    "\n",
    "reduction = 'Iteration'\n",
    "row = 'Measure Type'\n",
    "column = 'Submission Function'\n",
    "reference_column = 'submission_1_20224397'\n",
    "\n",
    "custom_fmt_template = '{mean_fmt} ¬± {std_fmt} {significance}'\n",
    "significance_levels = [0.1, 0.05, 0.01]\n",
    "decimal_places = 3\n",
    "transpose = True\n",
    "make_tables(csv_filename, keep_columns, keep_measures, reduction, row, column,  \n",
    "            reference_column, custom_fmt_template, significance_levels, decimal_places, transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f0a89-b0b6-4406-9500-24156dabcfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
